## Последовательности

В этом разделе мы рассмотрим АТД "последовательность", его реализацию при помощи
массивов и связанных списков, а также два специальных вида последовательностей:
стеки, где элементы вставляются и удаляются только на одном конце последовательности,
и очереди, когда элементы добавляются на одном конце последовательности, а удаляются
на другом. Последовательности часто служат основой для реализации более сложных
нелинейных структур данных.


### 1. АТД "последовательность элементов типа $T$". Массивы и связанные списки

Последовательность элементов типа $T$ (${\tt Seq}\langle T \rangle$) -- это АТД, инкапсулирующий множество
элементов типа $T$ плюс порядок их следования: $a_1, a_2, \ldots, a_n$.
Если $n = 0$, то имеем пустую последовательность.

Чисто алгебраически последовательность представляет собой функцию $1..n \mapsto T$.
С точки зрения хранения данных, имеем $n$ элементов типа $T$, хранящихся в ячейках
памяти $@a[1], @a[2], \ldots, @a[n] : \#{\tt Seq}\langle T\rangle$. Если указанные ячейки расположены в памяти
друг за другом и имеют одинаковый размер (их адреса образуют арифметическую прогрессию),
то имеем *массив*, каждый элемент которого $a[i]$ можно считать и заменить
за небольшое время в модели памяти RAM с произвольным доступом.
*Одномерный массив* -- это последовательность $n$ однотипных элементов, расположенных
подряд в оперативной памяти компьютера, доступ к которым выполняется по значению
так называемого *индекса* массива.

$$
{\tt T[]}\; a \leftarrow {\bf new}\; T[1..n]
$$

![Рис. 1](/images/algorithms/sequences/array.png)

К недостаткам массивов можно отнести долгое время вставки и удаления элементов. Если операций
вставки и удаления довольно много, оптимальнее может оказаться использовать связанные списки.
*Связанный список* -- это последовательность несколько элементов данных, называемых
*узлами*. В каждом узле хранится информация двух видов: собственно данные узла
и одна или несколько ссылок на другие узлы связанного списка, называемых
*указателями*. Если текущий узел связанного списка является последним, в него
помещается т.н. нулевой указатель со специальным значением NULL; это говорит
о том, что указатель ни на что не указывает. В *однонаправленном связанном списке*
каждый узел содержит только один указатель, в который помещается ссылка на следующий
элемент списка, либо "ноль", если текущий элемент является последним.

$$
\#{\tt List}\langle T\rangle = \{ {\tt data}: T;\; {\tt next}: \#{\tt List}\langle T\rangle \}
$$

![Рис. 2](/images/algorithms/sequences/list1.png)

Для обращения к заданному элементу связанного списка необходимо выбрать
первый узел списка, а затем перемещаться по цепочке элементов до достижения
нужного узла. Поэтому, в отличие от одномерных массивов, время, затрачиваемое
на доступ к произвольному элементу однонаправленного списка зависит от его
положения в списке. Это является существенным недостатком связанного списка.
Однако у него есть и преимущество. Оно заключается в том, что для элементов
связанного списка не требуется предварительное резервирование оперативной
памяти компьютера. Кроме того, вставка и удаление элементов списка не представляют
особого труда и выполняются достаточно быстро изменением значений нескольких
указателей.

Если заранее неизвестно, сколько памяти потребуется для массива, применяют *динамические массивы*,
которые могут изменять свой размер в ходе выполнения программы. Для оптимизации процедуры копирования
массива в новый выделенный блок памяти для хранения элементов массива оставляют место и увеличивают/уменьшают
размер массива только вдвое -- тогда при вставке $N$ элементов придется скопировать весь массив $\log N$ раз [Лудов; Скиена, с. 85].

Существует модификация структуры однонаправленного связанного списка, которая
называется *двунаправленным связанным списком*. Отличие между ними в том, что
каждый узел двунаправленного списка (кроме первого и последнего) содержит
указатели на предыдущий и последующий узлы.

$$
\#{\tt List}\langle T\rangle = \{ {\tt data}: T;\; {\tt next, prev}: \#{\tt List}\langle T\rangle \}
$$

![Рис. 3](/images/algorithms/sequences/list2.png)

Здесь $\#{\tt List}\langle T\rangle$ -- то же, что $@{\tt ListElem}$.


### 2. АТД "стек" и "очередь"

*Стеком* (stack) называют такую последовательность, в которой можно удалить только последний
элемент, а новый элемент добавить только в его конец. Последний часто
называют *вершиной* стека, поскольку стеки обычно изображают на рисунках
в виде вертикального прямоугольника (по аналогии со стопкой тарелок, которую
он напоминает). Кратко сформулировать принцип работы стека можно так: 
"последним вошел, первым вышел" ("last-in-first-out", или LIFO), поскольку первым
из стека всегда удаляется элемент, добавленный в него последним. Этим стек
напоминает стопку тарелок, поскольку мы можем взять из нее только верхнюю
тарелку, а новую тарелку — положить на верх стопки. Стеки широко 
применяются на практике, в частности, без них не обойтись при реализации рекурсивных
алгоритмов.

Нетрудно реализовать стек емкостью не более $n$ элементов на базе массива $S[1..n]$.
Наряду с массивом мы храним число ${\tt top}$, являющееся индексом последнего добавленного
в стек элемента. Стек состоит из элементов $S[1..{\tt top}]$, где $S[1]$ -- нижний элемент
стека ("дно"), а $S[top]$ -- верхний элемент, или вершина стека.
Если ${\tt top} = 0$, то стек пуст. Если ${\tt top} = n$, то при попытке добавить элемент
происходит переполнение (ошибка). Также ошибка возникает при попытке удалить элемент из
пустого стека. Реализацию стека см. в [КЛРШ, с. 265], [Ахо, с. 60].

Под *очередью* (queue) понимается такая последовательность, элементы которой 
удаляются с одной стороны структуры (она называется головой (front)), а добавляются
с другой (она называется хвостом (rear)). Первая операция называется 
удалением элемента из очереди (dequeue), а вторая — постановкой в очередь (enqueue).
Таким образом, принцип работы очереди можно сформулировать так: "первым
вошел, первым вышел" ("first-in-first-out", или FIFO). Здесь прослеживается 
полная аналогия с очередью в магазине, которая образуется, если продавец медленно
отпускает товар или наплыв покупателей слишком велик. Очереди также находят
широкое практическое применение, в частности, в некоторых алгоритмах решения
задач теории графов.

Покажем, как реализовать очередь, вмещающую не более чем $n-1$ элементов, на базе (циклического) массива
$Q[1..n]$. Мы храним числа ${\tt head}$ -- индекс головы очереди, и ${\tt tail}$ -- индекс
свободной ячейки, в которую будет помещен следующий добавляемый к очереди элемент.
Очередь состоит из элементов массива, стоящих в местах с номерами ${\tt head}, {\tt head} + 1, \ldots {\tt tail} - 1$
(подразумевается, что массив свернут в кольцо: за $n$ следует 1$).
Первоначально имеем ${\tt head} = {\tt tail} = 1$. Если очередь пуста, попытка удалить элемент из нее
ведет к ошибке; если ${\tt head} = {\tt tail} + 1$, то очередь полностью заполнена, и попытка добавить к ней элемент
вызовет переполнение. Заметим, что прибавление 1 к индексу циклического массива следует реализовать так:
$i \bmod n + 1$.
Реализацию стека см. в [КЛРШ, с. 197], [Ахо, с. 63].

В [Луридас, с. 19] приводится пример задачи, в которой требуется найти промежуток
времени, в течение которого цена на акции была меньше текущей (то есть для каждого элемента
последовательности как бы просмотреть ее в обратном порядке и остановиться на ближайшем
элементе, когда цена была не меньше, чем сейчас). Для эффективного решения этой
задачи использовался стек: все такие $a[j]$, для которых среди $a[1..i]$ найдется
$a[k] \geq a[j]$, удаляются из стека, как только нашелся элемент, больший данного и находящийся в последовательности правее него.
Инвариант: в стеке хранится невозрастающая подпоследовательность последовательности $a[1..i]$,
то есть для каждого $a[j]$ удалены все предшествующие $a[k+1..j-1]$, для которых $a[.] < a[j]$.
На каждом шаге алгоритм извлекает из стека все дни, в которые цена на акции была меньше текущей,
тогда при добавлении текущего дня в стек инвариант сохранится.
Каждый элемент последовательности $a[1..n]$ будет однажды добавлен в стек и
однажды извлечен из стека, и других долгих операций алгоритм не требует.
Следовательно, временная сложность алгоритма $O(n)$ – по числу элементов,
добавленных в стек.


### 3. АТД "упорядоченная последовательность элементов типа $T$"

В такой структуре данных необходимо поддерживать инвариант -- упорядоченность
последовательности по возрастанию (или по убыванию). В таком случае поиск
заданного элемента в упорядоченном массиве можно произвести за время $O(\log n)$
при помощи метода деления массива пополам (двоичный поиск).

Дана упорядоченная по неубыванию последовательность $s[1], s[2], \ldots, s[n]$.
Требуется найти множество $\{i \colon s[i] = x\}$.

Пространство поиска: $X = a..b$, $a < b$.

$c = \left[\dfrac{a+b}{2}\right] \; \Rightarrow \; c \leq b-1$

$X = Y \cup Z$, $Y \cap Z = \varnothing$,$\;\;$ $Y = a..c$, $Z = c+1..b$

Если $s[c] < x$, то $s[i] < x \; \,\forall\, i \in Y \; \Rightarrow \; X \leftarrow Z$.

Если $s[c] > x$, то $s[i] > x \; \,\forall\, i \in Z \; \Rightarrow \; X \leftarrow Y$.

Если $s[c] = x$, то пройти влево и вправо от $i = c$, пока $s[i] = x$.


### Литература

[Левитин] [Левитин -- Алгоритмы: введение в разработку и анализ (2006)](https://yadi.sk/i/1IkcA145-decvg) -- С. 54-58

[Ахо] [Ахо, Хопкрофт, Ульман -- Структуры данных и алгоритмы (2000)](https://yadi.sk/i/S0l1uKNKi7r1Pg) -- С. 45-66

[КЛРШ] [Кормен, Лейзерсон, Ривест, Штайн -- Алгоритмы: Построение и анализ (2013)](https://disk.yandex.ru/i/3y3lloOX_yz3rA) -- С. 264-272

[Скиена] [Скиена - Алгоритмы. Руководство по разработке (2011)](https://disk.yandex.ru/i/RSTnNYzSvWlgrA)

[Лудов] [Лудов - Введение в структуры данных (2008)](https://disk.yandex.ru/i/n_KkX6IZ-cZpoA)

[Луридас] [Луридас -- Алгоритмы для начинающих. Теория и практика для разработчика (2018)](https://yadi.sk/i/J0mS63RpEhH8tw)